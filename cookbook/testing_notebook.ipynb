{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from glob import glob\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from monai.data import CacheDataset, DataLoader\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, EnsureTyped,\n",
    "    Orientationd, Spacingd, NormalizeIntensityd, ResizeWithPadOrCropd\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "from preprocess.utils.RepeatChannel import RepeatChannelsd\n",
    "from tomultichannel import ConvertToMultiChannel\n",
    "from model_builder import UNet3D\n",
    "# from U_Mamba_net import U_Mamba_net   # <- for later if you want\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_determinism(seed=0)\n",
    "\n",
    "NUM_WORKERS = 1\n",
    "\n",
    "# ---- CHANGE THESE ----\n",
    "MODEL_PATH = \"/home/luudh/luudh/MyFile/medical_image_lab/monai/going_modular/model/UNet3D.pth\"\n",
    "IMAGES_DIR = \"/home/luudh/luudh/MyFile/medical_image_lab/monai/data/Task01_BrainTumour/imagesVal\"\n",
    "LABELS_DIR = \"/home/luudh/luudh/MyFile/medical_image_lab/monai/data/Task01_BrainTumour/labelsVal\"\n",
    "RESULTS_CSV = \"preliminary_dice_unet.csv\"\n",
    "# ----------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c3eb149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_eval_dataset():\n",
    "    val_images = sorted(glob(os.path.join(IMAGES_DIR, \"*.nii.gz\")))\n",
    "    val_labels = sorted(glob(os.path.join(LABELS_DIR, \"*.nii.gz\")))\n",
    "\n",
    "    assert len(val_images) == len(val_labels), \\\n",
    "        f\"Found {len(val_images)} images but {len(val_labels)} labels.\"\n",
    "\n",
    "    val_data = [{\"image\": i, \"label\": l} for i, l in zip(val_images, val_labels)]\n",
    "\n",
    "    val_transforms = Compose([\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            pixdim=(1.0, 1.0, 1.0),\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "        ),\n",
    "        NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        ResizeWithPadOrCropd(keys=[\"image\", \"label\"], spatial_size=(240, 240, 144)),\n",
    "        RepeatChannelsd(keys=[\"image\"], target_channels=4),   # 4 MRI modalities\n",
    "        ConvertToMultiChannel(keys=\"label\"),                  # 3 channels (WT/TC/ET etc.)\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "    ])\n",
    "\n",
    "    val_ds = CacheDataset(\n",
    "        data=val_data,\n",
    "        transform=val_transforms,\n",
    "        cache_rate=0.1,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "    return val_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "168413f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_unet3d():\n",
    "    model = UNet3D(in_channels=4, out_channels=3).to(device)\n",
    "\n",
    "    # IMPORTANT: explicitly set weights_only=False for PyTorch 2.6+\n",
    "    checkpoint = torch.load(\n",
    "        MODEL_PATH,\n",
    "        map_location=device,\n",
    "        weights_only=False,   # <- add this\n",
    "    )\n",
    "\n",
    "    # handle both types: full checkpoint dict or raw state_dict\n",
    "    if isinstance(checkpoint, dict) and \"model_state_dict\" in checkpoint:\n",
    "        state_dict = checkpoint[\"model_state_dict\"]\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "\n",
    "    # strip \"module.\" if saved with DDP\n",
    "    new_state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(new_state_dict, strict=False)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67253c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import Activations, AsDiscrete\n",
    "\n",
    "def evaluate_model(model, val_ds, results_csv=RESULTS_CSV):\n",
    "    loader = DataLoader(val_ds, batch_size=1, num_workers=NUM_WORKERS)\n",
    "\n",
    "    # Post-processing: sigmoid + threshold -> binary masks\n",
    "    post_trans = Compose([\n",
    "        Activations(sigmoid=True),\n",
    "        AsDiscrete(threshold=0.5),\n",
    "    ])\n",
    "\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean_batch\")   # for overall\n",
    "    dice_per_case_metric = DiceMetric(include_background=False, reduction=\"none\")  # for per-case\n",
    "\n",
    "    per_case_scores = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(loader):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)  # already multi-channel (C=3)\n",
    "\n",
    "            logits = model(images)\n",
    "            preds = post_trans(logits)\n",
    "\n",
    "            # accumulate for overall Dice\n",
    "            dice_metric(y_pred=preds, y=labels)\n",
    "\n",
    "            # per-case Dice (shape: [B, C])\n",
    "            d_case = dice_per_case_metric(y_pred=preds, y=labels)\n",
    "            d_case_np = d_case.cpu().numpy().reshape(-1, d_case.shape[-1])  # (1, C)\n",
    "            per_case_scores.append(d_case_np)\n",
    "\n",
    "            print(f\"[{i+1}/{len(loader)}] Dice per class (case {i}):\", d_case_np[0])\n",
    "\n",
    "    mean_dice = dice_metric.aggregate().cpu().numpy()  # (C,)\n",
    "    dice_metric.reset()\n",
    "\n",
    "    print(\"\\n=== PRELIMINARY UNet RESULTS (Dice, include_background=False) ===\")\n",
    "    print(f\"Mean Dice per class: {mean_dice}\")\n",
    "    print(f\"Mean Dice (all classes): {mean_dice.mean():.4f}\")\n",
    "\n",
    "    # Save per-case Dice scores to CSV\n",
    "    if per_case_scores:\n",
    "        all_scores = np.vstack(per_case_scores)  # shape (N_cases, C)\n",
    "        header = \"class1,class2,class3\"\n",
    "        np.savetxt(results_csv, all_scores, delimiter=\",\", header=header, comments=\"\")\n",
    "        print(f\"Per-case Dice scores saved to: {results_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32ec632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Building evaluation dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 4/4 [00:04<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Validation/Test set size: 48 cases\n",
      "[INFO] Loading UNet3D model...\n",
      "[INFO] Evaluating model...\n",
      "[1/48] Dice per class (case 0): [0.75157905 0.4251383 ]\n",
      "[2/48] Dice per class (case 1): [0.8002038  0.16205518]\n",
      "[3/48] Dice per class (case 2): [0.82215244 0.16976556]\n",
      "[4/48] Dice per class (case 3): [0.5495274  0.09812512]\n",
      "[5/48] Dice per class (case 4): [0.66676384 0.08962226]\n",
      "[6/48] Dice per class (case 5): [0.5249975  0.06016559]\n",
      "[7/48] Dice per class (case 6): [0.59487194 0.01662111]\n",
      "[8/48] Dice per class (case 7): [0.60108054 0.25122195]\n",
      "[9/48] Dice per class (case 8): [0.54279864 0.05440509]\n",
      "[10/48] Dice per class (case 9): [0.43135354 0.0962012 ]\n",
      "[11/48] Dice per class (case 10): [0.85900724 0.05353356]\n",
      "[12/48] Dice per class (case 11): [0.38332075 0.16988166]\n",
      "[13/48] Dice per class (case 12): [0.57058936 0.04916548]\n",
      "[14/48] Dice per class (case 13): [0.34758857 0.00047921]\n",
      "[15/48] Dice per class (case 14): [0.6942916  0.06638841]\n",
      "[16/48] Dice per class (case 15): [0.51774704 0.1013986 ]\n",
      "[17/48] Dice per class (case 16): [0.74999124 0.00966524]\n",
      "[18/48] Dice per class (case 17): [0.73460156 0.1940088 ]\n",
      "[19/48] Dice per class (case 18): [0.3914831  0.30850953]\n",
      "[20/48] Dice per class (case 19): [0.41210383 0.05676747]\n",
      "[21/48] Dice per class (case 20): [0.5808435  0.10069743]\n",
      "[22/48] Dice per class (case 21): [0.43422353 0.1555741 ]\n",
      "[23/48] Dice per class (case 22): [0.4784241  0.09760524]\n",
      "[24/48] Dice per class (case 23): [0.13509658 0.00071529]\n",
      "[25/48] Dice per class (case 24): [0.4671248 0.3196571]\n",
      "[26/48] Dice per class (case 25): [0.5935128  0.15184131]\n",
      "[27/48] Dice per class (case 26): [0.58414537 0.10420518]\n",
      "[28/48] Dice per class (case 27): [0.76049656 0.11109485]\n",
      "[29/48] Dice per class (case 28): [0.21357438 0.08976157]\n",
      "[30/48] Dice per class (case 29): [0.60263896 0.04628445]\n",
      "[31/48] Dice per class (case 30): [0.2399452  0.10632788]\n",
      "[32/48] Dice per class (case 31): [0.68690646 0.06845562]\n",
      "[33/48] Dice per class (case 32): [0.39920223 0.07953294]\n",
      "[34/48] Dice per class (case 33): [0.79389715 0.14116049]\n",
      "[35/48] Dice per class (case 34): [0.468806   0.01461412]\n",
      "[36/48] Dice per class (case 35): [0.27990848 0.03307087]\n",
      "[37/48] Dice per class (case 36): [0.6412607  0.05220233]\n",
      "[38/48] Dice per class (case 37): [0.4014549  0.09517793]\n",
      "[39/48] Dice per class (case 38): [0.8162837 0.1541254]\n",
      "[40/48] Dice per class (case 39): [0.8737379 0.0873759]\n",
      "[41/48] Dice per class (case 40): [0.74488205 0.00437657]\n",
      "[42/48] Dice per class (case 41): [0.460098   0.12860942]\n",
      "[43/48] Dice per class (case 42): [0.08046111 0.22331196]\n",
      "[44/48] Dice per class (case 43): [0.76782644 0.15908729]\n",
      "[45/48] Dice per class (case 44): [0.11946337 0.554943  ]\n",
      "[46/48] Dice per class (case 45): [0.6924635  0.01255553]\n",
      "[47/48] Dice per class (case 46): [0.28098312 0.08755365]\n",
      "[48/48] Dice per class (case 47): [0.5402862 0.1533784]\n",
      "\n",
      "=== PRELIMINARY UNet RESULTS (Dice, include_background=False) ===\n",
      "Mean Dice per class: [0.5434167  0.12013365]\n",
      "Mean Dice (all classes): 0.3318\n",
      "Per-case Dice scores saved to: preliminary_dice_unet.csv\n",
      "[INFO] Evaluation time: 60.1 seconds\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"[INFO] Building evaluation dataset...\")\n",
    "    val_ds = build_eval_dataset()\n",
    "    print(f\"[INFO] Validation/Test set size: {len(val_ds)} cases\")\n",
    "\n",
    "    print(\"[INFO] Loading UNet3D model...\")\n",
    "    model = load_unet3d()\n",
    "\n",
    "    print(\"[INFO] Evaluating model...\")\n",
    "    start = time.time()\n",
    "    evaluate_model(model, val_ds)\n",
    "    end = time.time()\n",
    "    print(f\"[INFO] Evaluation time: {end - start:.1f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c015e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from torch import nn\n",
    "\n",
    "from monai.data import Dataset, DataLoader, decollate_batch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, EnsureTyped, Orientationd,\n",
    "    Spacingd, NormalizeIntensityd, ResizeWithPadOrCropd,\n",
    "    AsDiscreted, Activationsd\n",
    ")\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import AsDiscrete, Activations\n",
    "\n",
    "# local imports\n",
    "from U_Mamba_net import U_Mamba_net\n",
    "from model_builder import UNet3D\n",
    "from preprocess.utils.RepeatChannel import RepeatChannelsd\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "#  Helpers\n",
    "# ----------------------\n",
    "\n",
    "def build_model(name: str, in_channels: int, num_classes: int, device: torch.device) -> nn.Module:\n",
    "    name = name.lower()\n",
    "    if name in {\"u_mamba\", \"mamba\", \"u-mamba\"}:\n",
    "        model = U_Mamba_net(in_channels=in_channels, num_classes=num_classes)\n",
    "    elif name in {\"unet\", \"unet3d\"}:\n",
    "        model = UNet3D(in_channels=in_channels, out_channels=num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model '{name}'. Choose from ['u_mamba','unet3d'].\")\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "def load_weights(model: nn.Module, ckpt_path: str) -> None:\n",
    "    # robust to PyTorch 2.6 weights_only change\n",
    "    try:\n",
    "        ckpt = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "    except TypeError:\n",
    "        # older PyTorch versions without weights_only argument\n",
    "        ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "\n",
    "    state = ckpt.get(\"model_state_dict\", ckpt)\n",
    "    new_state = {k.replace(\"module.\", \"\"): v for k, v in state.items()}\n",
    "    missing, unexpected = model.load_state_dict(new_state, strict=False)\n",
    "    if missing:\n",
    "        print(f\"[warn] Missing keys: {sorted(missing)[:10]} ...\")\n",
    "    if unexpected:\n",
    "        print(f\"[warn] Unexpected keys: {sorted(unexpected)[:10]} ...\")\n",
    "\n",
    "\n",
    "def make_preprocess(roi: Tuple[int, int, int], target_channels: int):\n",
    "    \"\"\"\n",
    "    Preprocess for BRATS-like images and labels.\n",
    "    Assumes labels are integer masks (0..C).\n",
    "    \"\"\"\n",
    "    return Compose([\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"], track_meta=True),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\"], pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n",
    "        Spacingd(keys=[\"label\"], pixdim=(1.0, 1.0, 1.0), mode=\"nearest\"),\n",
    "        NormalizeIntensityd(keys=[\"image\"], nonzero=True, channel_wise=True),\n",
    "        ResizeWithPadOrCropd(keys=[\"image\", \"label\"], spatial_size=roi),\n",
    "        RepeatChannelsd(keys=[\"image\"], target_channels=target_channels),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"], track_meta=True),\n",
    "    ])\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    p = argparse.ArgumentParser(description=\"3D brain tumor preliminary evaluation (Dice)\")\n",
    "    p.add_argument(\"--model\", default=\"u_mamba\", help=\"u_mamba or unet3d\")\n",
    "    p.add_argument(\"--weights\", required=True, help=\"Path to .pth checkpoint\")\n",
    "    p.add_argument(\"--images\", required=True, nargs=\"+\", help=\"Glob(s) or path(s) to image .nii/.nii.gz\")\n",
    "    p.add_argument(\"--labels\", required=True, nargs=\"+\", help=\"Glob(s) or path(s) to label .nii/.nii.gz\")\n",
    "    p.add_argument(\"--roi\", type=int, nargs=3, default=[128, 128, 64], help=\"Sliding-window ROI size\")\n",
    "    p.add_argument(\"--sw-batch\", type=int, default=1, help=\"Sliding window batch size\")\n",
    "    p.add_argument(\"--overlap\", type=float, default=0.3, help=\"Sliding window overlap [0-1]\")\n",
    "    p.add_argument(\"--channels\", type=int, default=4, help=\"Model input channels\")\n",
    "    p.add_argument(\"--num-classes\", type=int, default=3, help=\"Output channels/classes\")\n",
    "    p.add_argument(\"--activation\", choices=[\"sigmoid\", \"softmax\"], default=\"softmax\")\n",
    "    p.add_argument(\"--multilabel\", action=\"store_true\", help=\"Treat outputs as independent classes (sigmoid)\")\n",
    "    p.add_argument(\"--threshold\", type=float, default=0.5, help=\"Sigmoid threshold for multilabel\")\n",
    "    p.add_argument(\"--amp\", action=\"store_true\", help=\"Enable mixed precision\")\n",
    "    p.add_argument(\"--out-csv\", default=\"prelim_results.csv\", help=\"CSV file to store per-case Dice\")\n",
    "    return p.parse_args()\n",
    "\n",
    "\n",
    "def resolve_paths(patterns: List[str]) -> List[str]:\n",
    "    files = []\n",
    "    for pat in patterns:\n",
    "        files.extend(glob.glob(pat))\n",
    "    files = sorted(set(files))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files matched: {patterns}\")\n",
    "    return files\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "#  Main eval\n",
    "# ----------------------\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"[INFO] Using device: {device}\")\n",
    "\n",
    "    # model\n",
    "    model = build_model(args.model, in_channels=args.channels, num_classes=args.num_classes, device=device)\n",
    "    load_weights(model, args.weights)\n",
    "    model.eval()\n",
    "\n",
    "    # data\n",
    "    img_files = resolve_paths(args.images)\n",
    "    lbl_files = resolve_paths(args.labels)\n",
    "    if len(img_files) != len(lbl_files):\n",
    "        raise RuntimeError(f\"#images ({len(img_files)}) != #labels ({len(lbl_files)})\")\n",
    "\n",
    "    print(f\"[INFO] Found {len(img_files)} image/label pairs for evaluation.\")\n",
    "\n",
    "    data = [\n",
    "        {\"image\": i, \"label\": l, \"case_id\": os.path.basename(i)}\n",
    "        for i, l in zip(img_files, lbl_files)\n",
    "    ]\n",
    "\n",
    "    pre_tf = make_preprocess(tuple(args.roi), args.channels)\n",
    "    ds = Dataset(data=data, transform=pre_tf)\n",
    "    loader = DataLoader(ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "    # metrics\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean_batch\", get_not_nans=True)\n",
    "\n",
    "    # post-processing for metrics\n",
    "    if args.multilabel:\n",
    "        post_pred = Compose([\n",
    "            Activations(sigmoid=True),\n",
    "            AsDiscrete(threshold=args.threshold),\n",
    "        ])\n",
    "        post_label = AsDiscrete(threshold=0.5)  # assumes labels already 0/1 per channel if multilabel GT\n",
    "    else:\n",
    "        # standard multi-class softmax + argmax + one-hot\n",
    "        post_pred = Compose([\n",
    "            Activations(softmax=True),\n",
    "            AsDiscrete(argmax=True, to_onehot=args.num_classes),\n",
    "        ])\n",
    "        post_label = AsDiscrete(to_onehot=args.num_classes)\n",
    "\n",
    "    case_ids = []\n",
    "    per_case_dice = []  # [N, C]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            images = batch[\"image\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            case_id = batch[\"case_id\"][0]\n",
    "            case_ids.append(case_id)\n",
    "\n",
    "            # sliding-window inference\n",
    "            def _fwd(inp):\n",
    "                out = model(inp)\n",
    "                return out[0] if isinstance(out, (list, tuple)) else out\n",
    "\n",
    "            if device.type == \"cuda\" and args.amp:\n",
    "                with torch.amp.autocast(\"cuda\"):\n",
    "                    logits = sliding_window_inference(\n",
    "                        inputs=images,\n",
    "                        roi_size=tuple(args.roi),\n",
    "                        sw_batch_size=args.sw_batch,\n",
    "                        predictor=_fwd,\n",
    "                        overlap=args.overlap,\n",
    "                        mode=\"gaussian\",\n",
    "                    )\n",
    "            else:\n",
    "                logits = sliding_window_inference(\n",
    "                    inputs=images,\n",
    "                    roi_size=tuple(args.roi),\n",
    "                    sw_batch_size=args.sw_batch,\n",
    "                    predictor=_fwd,\n",
    "                    overlap=args.overlap,\n",
    "                    mode=\"gaussian\",\n",
    "                )\n",
    "\n",
    "            # decollate & post-process\n",
    "            logits_list = decollate_batch(logits)\n",
    "            labels_list = decollate_batch(labels)\n",
    "\n",
    "            preds = [post_pred(p) for p in logits_list]\n",
    "            labs = [post_label(l) for l in labels_list]\n",
    "\n",
    "            # update metric\n",
    "            dice_metric(y_pred=preds, y=labs)\n",
    "            # get per-case (for this batch size=1)\n",
    "            per_case = dice_metric.aggregate(reduction=\"none\").cpu().numpy()  # shape [B, C]\n",
    "            dice_metric.reset()  # reset because we're tracking per-case ourselves\n",
    "\n",
    "            per_case_dice.append(per_case[0])  # [C]\n",
    "\n",
    "    per_case_dice = np.stack(per_case_dice, axis=0)  # [N, C]\n",
    "    mean_per_class = per_case_dice.mean(axis=0)      # [C]\n",
    "    mean_dice = per_case_dice.mean()\n",
    "\n",
    "    # print summary\n",
    "    print(\"\\n=== Preliminary Dice Results ===\")\n",
    "    print(f\"Num cases: {len(case_ids)}\")\n",
    "    print(f\"Mean Dice (all classes, all cases): {mean_dice:.4f}\")\n",
    "    for c in range(args.num_classes):\n",
    "        print(f\"  Class {c}: mean Dice = {mean_per_class[c]:.4f}\")\n",
    "\n",
    "    # save CSV\n",
    "    import csv\n",
    "    print(f\"\\n[INFO] Saving per-case Dice to {args.out_csv}\")\n",
    "    with open(args.out_csv, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        header = [\"case_id\"] + [f\"class_{c}_dice\" for c in range(args.num_classes)]\n",
    "        writer.writerow(header)\n",
    "        for cid, dice_vec in zip(case_ids, per_case_dice):\n",
    "            writer.writerow([cid] + [float(x) for x in dice_vec])\n",
    "\n",
    "    print(\"[INFO] Done.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1825f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_ids, per_case_dice, mean_per_class, mean_dice = run_prelim_eval(\n",
    "    model_name=\"unet3d\",\n",
    "    weights_path=\"model/Medical_Image_UNet3D_fresh.pth\",\n",
    "    image_globs=[\"/home/luudh/.../imagesVal/*.nii.gz\"],\n",
    "    label_globs=[\"/home/luudh/.../labelsVal/*.nii.gz\"],\n",
    "    roi=(128, 128, 64),\n",
    "    num_classes=3,\n",
    "    activation=\"softmax\",\n",
    "    multilabel=False,\n",
    "    use_amp=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ec253e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
